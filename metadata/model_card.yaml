---
model_name: llama3-ragqa-8b-lora-v2
id: 0147-model-2.1.3.5
version: 2.1.3.5
architecture: LLaMA-3
parameter_size: 8B

base_model:
  name: meta-llama/Llama-3-8B
  url: https://huggingface.co/meta-llama/Llama-3-8B

fine_tuning:
  method: LoRA
  config:
    rank: 16
    learning_rate: 1e-5
    epochs: 3
    batch_size: 4
    optimizer: adamw
    scheduler: cosine

generation_settings:
  max_tokens: 512
  temperature: 0.7
  top_p: 0.95

training_datasets:
  - 0420-train-2.0.1.0
  - 0450-train-2.0.2.0
validation_datasets:
  - 0421-valid-2.0.1.0

staged_training: true

start_time: 2025-06-16T20:00:00+05:30
end_time: 2025-06-16T20:10:00+05:30
duration: 10 minutes 10 seconds

tags:
  - LoRA
  - LLaMA
  - QA
  - RAG
  - 8B
created_by: Ravindu Weerasinghe
created_at: 2025-06-16T20:14:00+05:30
license: apache-2.0
---
